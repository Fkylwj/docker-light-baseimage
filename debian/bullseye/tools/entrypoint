#!/usr/bin/python3 -u
# -*- coding: utf-8 -*-

from multiprocessing.connection import wait
import os
import os.path
import subprocess
import sys
import stat
import signal
import errno
import argparse
import time
import shlex
import json
import shutil
import tempfile
from datetime import datetime
from dotenv import load_dotenv

KILL_PROCESS_TIMEOUT = int(os.environ.get(
    "CONTAINER_KILL_PROCESS_TIMEOUT", 30))

KILL_ALL_PROCESSES_TIMEOUT = int(os.environ.get(
    "CONTAINER_KILL_ALL_PROCESSES_TIMEOUT", 30))

terminated_child_processes = {}

LOG_LEVEL_NONE = 0
LOG_LEVEL_ERROR = 1
LOG_LEVEL_WARNING = 2
LOG_LEVEL_INFO = 3
LOG_LEVEL_DEBUG = 4
LOG_LEVEL_TRACE = 5

log_level_switcher = {"none": LOG_LEVEL_NONE, "error": LOG_LEVEL_ERROR, "warning": LOG_LEVEL_WARNING,
                      "info": LOG_LEVEL_INFO, "debug": LOG_LEVEL_DEBUG, "trace": LOG_LEVEL_TRACE}

log_level_switcher_inv = {v: k for k, v in log_level_switcher.items()}

# Keep sync with values in log-helper file.
log_level = LOG_LEVEL_INFO
log_json = False

ENVIRONMENT_LOG_LEVEL_KEY = "CONTAINER_LOG_LEVEL"
ENVIRONMENT_LOG_FORMAT_KEY = "CONTAINER_LOG_FORMAT"

ENVIRONMENT_IMAGE_NAME_KEY = "CONTAINER_IMAGE_NAME"
ENVIRONMENT_IMAGE_TAG_KEY = "CONTAINER_IMAGE_TAG"

ENVIRONMENT_FILES_IMPORT_DIR = "/container/environment"
ENVIRONMENT_FILES_PREFIX = (".env")

# Keep sync with values in install-services file.
ENTRYPOINT_DIR = "/container/entrypoint"
ENTRYPOINT_STARTUP_DIR = ENTRYPOINT_DIR + "/startup"
ENTRYPOINT_PROCESS_DIR = ENTRYPOINT_DIR + "/process"
ENTRYPOINT_FINISH_DIR = ENTRYPOINT_DIR + "/finish"

ENTRYPOINT_SUBDIRS = [ENTRYPOINT_STARTUP_DIR, ENTRYPOINT_PROCESS_DIR, ENTRYPOINT_FINISH_DIR]

TEMPLATES_DIR = "/container/templates"
GENERATOR_DIR = "/container/generator"


class AlarmException(Exception):
    pass


def write_log(level, message):
    now = datetime.now().isoformat()

    if log_json:
        dictionary = {"datetime": now,
                      "level": level.strip(), "message": message.strip()}
        sys.stderr.write("%s\n" % json.dumps(dictionary))
        return

    for line in message.splitlines():
        sys.stderr.write("*** %s | %s | %s\n" % (now, level, line.rstrip()))


def error(message):
    if log_level >= LOG_LEVEL_ERROR:
        write_log(" ERROR ", message)


def warning(message):
    if log_level >= LOG_LEVEL_WARNING:
        write_log("WARNING", message)


def info(message):
    if log_level >= LOG_LEVEL_INFO:
        write_log(" INFO  ", message)


def debug(message):
    if log_level >= LOG_LEVEL_DEBUG:
        write_log(" DEBUG ", message)


def trace(message):
    if log_level >= LOG_LEVEL_TRACE:
        write_log(" TRACE ", message)


def ignore_signals_and_raise_keyboard_interrupt(signame):
    signal.signal(signal.SIGTERM, signal.SIG_IGN)
    signal.signal(signal.SIGINT, signal.SIG_IGN)
    raise KeyboardInterrupt(signame)


def raise_alarm_exception():
    raise AlarmException("Alarm")


def listdir(path):
    try:
        result = os.stat(path)
    except OSError:
        return []
    if stat.S_ISDIR(result.st_mode):
        return sorted(os.listdir(path))
    else:
        return []


def is_exe(path):
    try:
        return os.path.isfile(path) and os.access(path, os.X_OK)
    except OSError:
        return False


def xstr(s):
    if s is None:
        return ""
    return str(s)


def generator(args):
    if not args.generate and not args.generate_multiprocess and not args.generate_child and not args.generate_service and not args.generate_service_available:
        return

    if is_single_process_container() or is_multiprocess_container():
        if args.generate or args.generate_multiprocess:
            error("--generate or --generate-multiprocess can't be used on images with existing process, use --generate-child instead.")
            sys.exit(1)

    else:
        if args.generate_child:
            error("--generate-child can't be used on images without any existing process, use --generate or --generate-multiprocess instead.")
            sys.exit(1)
        
        if args.generate and args.generate_multiprocess:
            error("--generate option can't be used with --generate-multiprocess set at the same time.")
            sys.exit(1)

    if (args.generate or args.generate_multiprocess or args.generate_child) and (args.generate_service or args.generate_service_available):
        error("--generate-service and --generate-service-available options can't be used with --generate, --generate-multiprocess or --generate-child set at the same time.")
        sys.exit(1)

    generator_print_files = False

    if not os.path.isdir(GENERATOR_DIR):
        generator_print_files = True

        warning("Generator directory not found: %s. Generated files will be printed to the console." %
                GENERATOR_DIR)
        warning("To get generated files directly on your file system mount a host directory to %s." %
                GENERATOR_DIR)
        warning("docker run --rm --volume $(pwd)/example:%s %s %s" % (GENERATOR_DIR,
                get_container_image(), get_generator_command_line_options(args)))

        try:
            os.mkdir(GENERATOR_DIR)
        except OSError as e:
            error("Error creating %s directory" % GENERATOR_DIR)
            sys.exit(1)

    try:
        if args.generate:
            generate(args.generate)

        elif args.generate_multiprocess:
            generate_multiprocess(args.generate_multiprocess)

        elif args.generate_child:
            generate_child(args.generate_child)

        if args.generate_service:
            for service in args.generate_service:
                generate_service(service)

        if args.generate_service_available:
            for service_available in args.generate_service_available:
                generate_service_available(service_available)

    except Exception as e:
            error(e)
            sys.exit(1)

    if generator_print_files:
        separator = "--------------------------------------------------------------------------------"

        for subdir, _, files in os.walk(GENERATOR_DIR):
            for file in files:
                file_path = os.path.join(subdir, file)

                print(separator)
                print("file: %s" % file_path.replace(GENERATOR_DIR, ""))
                print("content:\n")

                with open(file_path, "r") as f:
                    print(f.read())

    sys.exit(0)


def get_generator_command_line_options(args):
    options = ""

    if(args.generate):
        options += "--generate %s " % args.generate

    if(args.generate_multiprocess):
        options += "--generate-multiprocess %s " % args.generate_multiprocess

    if(args.generate_child):
        options += "--generate-child %s " % args.generate_child

    if args.generate_service:
        for service in args.generate_service:
            options += "--generate-service %s " % service

    if args.generate_service_available:
        for service_available in args.generate_service_available:
            options += "--generate-service-available %s " % service_available

    return options


def generate_envsubst_templates(source, dest=None, environ=None):
    # change log level to warning for envsubst-templates
    subprocess_environ = os.environ.copy()
    subprocess_environ[ENVIRONMENT_LOG_LEVEL_KEY] = xstr(LOG_LEVEL_WARNING)

    if not os.path.isdir(os.path.join(ENVIRONMENT_FILES_IMPORT_DIR, "00-default")):
        subprocess_environ["ENVIRONMENT_DIRECTORY"] = "00-default"
    else:
        subprocess_environ["ENVIRONMENT_DIRECTORY"] = "xx-some-dir"

    if environ:
        subprocess_environ = subprocess_environ | environ

    if dest:
        dest = os.path.join(GENERATOR_DIR, dest)
    else:
        dest = GENERATOR_DIR

    subprocess.run("envsubst-templates %s %s" %
                   (source, dest), shell=True, check=True, env=subprocess_environ)


# generate single process image files
def generate(option, service_name="service-1"):
    debug("Generate single process templates")
    with tempfile.TemporaryDirectory() as tmpdir:
        trace("Use temporary directory: %s" % tmpdir)

        if option == "dockerfile":
            shutil.copy(os.path.join(TEMPLATES_DIR,
                        "Dockerfile.template"), tmpdir)
        else:
            shutil.copy(os.path.join(TEMPLATES_DIR,
                        "image_name.cue.template"), tmpdir)

        shutil.copytree(os.path.join(TEMPLATES_DIR, "environment"),
                        os.path.join(GENERATOR_DIR, "environment"))

        generate_envsubst_templates(tmpdir)

    generate_service(service_name, "services")


def generate_multiprocess(option):

    generate(option, "service-1")
    generate_service("service-2", "services")

    files_to_remove = [os.path.join(GENERATOR_DIR, "Dockerfile"), os.path.join(GENERATOR_DIR, "image_name.cue")]
    for file in files_to_remove:
        if os.path.isfile(file):
            debug("Remove single process generated files: %s" % file)
            os.remove(file)

    debug("Generate multiprocess templates")
    with tempfile.TemporaryDirectory() as tmpdir:
        trace("Use temporary directory: %s" % tmpdir)

        if option == "dockerfile":
            shutil.copy(os.path.join(TEMPLATES_DIR, "Dockerfile.multiprocess.template"), os.path.join(
                tmpdir, "Dockerfile.template"))
        else:
            shutil.copy(os.path.join(TEMPLATES_DIR, "image_name.cue.multiprocess.template"), os.path.join(
                tmpdir, "image_name.cue.template"))

        generate_envsubst_templates(tmpdir)


def generate_child(option):
    if is_single_process_container():
        generate_multiprocess(option)
    else:
        generate(option, "service-1")

def generate_service(name, in_dir=None):
    debug("Generate service templates: %s" % name)
    with tempfile.TemporaryDirectory() as tmpdir:
        trace("Use temporary directory: %s" % tmpdir)

        shutil.copytree(os.path.join(TEMPLATES_DIR, "services", "service-name"),
                        os.path.join(tmpdir, name))

        generate_envsubst_templates(tmpdir, in_dir, {"SERVICE_NAME": name})


def generate_service_available(name, in_dir=None):

    generate_service(name, in_dir)

    debug("Generate service-available templates: %s" % name)
    with tempfile.TemporaryDirectory() as tmpdir:
        trace("Use temporary directory: %s" % tmpdir)

        shutil.copytree(os.path.join(
            TEMPLATES_DIR, "services-available", "service-available-name"), os.path.join(tmpdir, name))

        generate_envsubst_templates(tmpdir, in_dir, {"SERVICE_NAME": name})


def import_env_files():
    if not os.path.exists(ENVIRONMENT_FILES_IMPORT_DIR):
        warning("%s directory don't exists" % ENVIRONMENT_FILES_IMPORT_DIR)
        return

    env_backup = dict(os.environ)

    for subdir, _, files in os.walk(ENVIRONMENT_FILES_IMPORT_DIR):
        for file in sorted(files):
            if file.startswith(ENVIRONMENT_FILES_PREFIX):

                filepath = os.path.join(subdir, file)

                info("Loading environment file %s ..." % filepath)
                load_dotenv(filepath, override=True)
                set_env(env_backup)


def set_env(env):
    for k, v in env.items():
        if v is not None:
            os.environ[k] = v


def set_log_env():
    trace("Setting container logs environment variables ...")

    log_level_message = "Increase log level to \"debug\" or \"trace\" to dump all container environment variables."
    if log_level >= LOG_LEVEL_DEBUG:
        log_level_message = ""

    info("%s=%s (%s) %s" % (ENVIRONMENT_LOG_LEVEL_KEY, log_level,
         log_level_switcher_inv.get(log_level), log_level_message))
    os.environ[ENVIRONMENT_LOG_LEVEL_KEY] = xstr(log_level)

    log_format = "CONSOLE"
    log_format_message = "Run container with command argument --logjson to switch to JSON log format."
    if log_json:
        log_format = "JSON"
        log_format_message = ""

    info("%s=%s %s" % (ENVIRONMENT_LOG_FORMAT_KEY,
         log_format, log_format_message))
    os.environ[ENVIRONMENT_LOG_FORMAT_KEY] = log_format


def dump_env():
    message = "Environment variables:\n"
    for name, value in list(os.environ.items()):
        message += "%s=%s\n" % (name, value)
    return message


def get_container_image():
    return "%s:%s" % (os.environ.get(ENVIRONMENT_IMAGE_NAME_KEY, "undefined"), os.environ.get(ENVIRONMENT_IMAGE_TAG_KEY, "undefined"))


def process_exists(service_name):
    for entrypoint_subdir in ENTRYPOINT_SUBDIRS:
        process = os.path.join(entrypoint_subdir, service_name, "run")

        if os.path.exists(process):
            return True

    return False


def process_list():
    services = []
    for entrypoint_subdir in ENTRYPOINT_SUBDIRS:
        services += listdir(entrypoint_subdir)
    return list(dict.fromkeys(services))


def is_multiprocess_container():
    return len(listdir(ENTRYPOINT_PROCESS_DIR)) > 1


def is_single_process_container():
    return len(listdir(ENTRYPOINT_PROCESS_DIR)) == 1


# Waits for the child process with the given PID, while at the same time
# reaping any other child processes that have exited (e.g. adopted child
# processes that have terminated).
def waitpid_reap_other_children(pid):
    global terminated_child_processes

    status = terminated_child_processes.get(pid)
    if status:
        # A previous call to waitpid_reap_other_children(),
        # with an argument not equal to the current argument,
        # already waited for this process. Return the status
        # that was obtained back then.
        del terminated_child_processes[pid]
        return status

    done = False
    status = None
    while not done:
        try:
            # https://github.com/phusion/baseimage-docker/issues/151#issuecomment-92660569
            this_pid, status = os.waitpid(pid, os.WNOHANG)
            if this_pid == 0:
                this_pid, status = os.waitpid(-1, 0)
            if this_pid == pid:
                done = True
            else:
                # Save status for later.
                terminated_child_processes[this_pid] = status
        except OSError as e:
            if e.errno == errno.ECHILD or e.errno == errno.ESRCH:
                return None
            else:
                raise
    return status


def stop_child_process(name, pid, signo=signal.SIGTERM, time_limit=KILL_PROCESS_TIMEOUT):
    info("Shutting down %s (PID %d) ..." % (name, pid))
    try:
        os.kill(pid, signo)
    except OSError:
        pass
    signal.alarm(time_limit)
    try:
        try:
            waitpid_reap_other_children(pid)
        except OSError:
            pass
    except AlarmException:
        warning(
            "%s (PID %d) did not shut down in time. Forcing it to exit." % (name, pid))
        try:
            os.kill(pid, signal.SIGKILL)
        except OSError:
            pass
        try:
            waitpid_reap_other_children(pid)
        except OSError:
            pass
    finally:
        signal.alarm(0)


def kill_all_processes(time_limit):
    info("Killing all processes ...")
    try:
        os.kill(-1, signal.SIGTERM)
    except OSError:
        pass
    signal.alarm(time_limit)
    try:
        # Wait until no more child processes exist.
        done = False
        while not done:
            try:
                os.waitpid(-1, 0)
            except OSError as e:
                if e.errno == errno.ECHILD:
                    done = True
                else:
                    raise
    except AlarmException:
        warning("Not all processes have exited in time. Forcing them to exit.")
        try:
            os.kill(-1, signal.SIGKILL)
        except OSError:
            pass
    finally:
        signal.alarm(0)


def run_scripts(dir, run_only_service = ""):
    for name in listdir(dir):
        if run_only_service and name != run_only_service:
            continue

        dirname = os.path.join(dir, name)
        filename = os.path.join(dirname, 'run')
        if is_exe(filename):
            run_command([filename])


def run_background_command(command, display_name = None):
    if not display_name:
        display_name = " ".join(command)

    info("Running %s ..." % display_name)
    pid = os.spawnvp(os.P_NOWAIT, command[0], command)
    debug("%s started as PID %d" % (display_name, pid))
    return display_name, pid


def wait_background_process(name, pid):
    exit_status = waitpid_reap_other_children(pid)

    if exit_status is None:
        warning("%s exited with unknown status" % name)
        return 1
    else:
        log_message = "%s exited with status %d"
        if exit_status != 0:
            warning(log_message % (name, exit_status))
        else:
            debug(log_message % (name, exit_status))
        return os.WEXITSTATUS(exit_status)


def run_command(command):
    exit_status = None

    name, pid = run_background_command(command)
    try:
        exit_status = wait_background_process(name, pid)
    except KeyboardInterrupt:
        stop_child_process(name, pid)
        raise
    except BaseException:
        error("An error occurred. Aborting.")
        stop_child_process(name, pid)
        raise

    return exit_status


def shutdown_runit_services():
    debug("Begin shutting down services ...")
    subprocess.run("/usr/bin/sv -w %d force-stop %s/* > /dev/null" %
                   (KILL_PROCESS_TIMEOUT, ENTRYPOINT_PROCESS_DIR), shell=True)


def wait_runit_services_shutdown():
    info("Waiting for services to exit ...")
    done = False
    while not done:
        done = subprocess.run("/usr/bin/sv status %s/* | grep -q '^run:'" %
                              ENTRYPOINT_PROCESS_DIR, shell=True).returncode != 0
        if not done:
            time.sleep(0.1)
            shutdown_runit_services()


def run_main_command_or_wait_background_process(main_command, background_process_name, background_process_pid):
    background_process_exited = False
    exit_status = None
    
    if len(main_command) == 0:
        exit_status = wait_background_process(
            background_process_name, background_process_pid)
        background_process_exited = True
    else:
        exit_status = run_command(args.main_command)

    return background_process_exited, exit_status


def run_multiprocess_container(main_command, restart_processes):
    if not os.path.exists("/usr/bin/sv"):
        error("Runit is not installed and this is a multiprocess container.")
        sys.exit(1)

    runit_process_exited = False
    runit_process_name = None
    runit_process_pid = None
    exit_status = None

    try:
        runit_process_name, runit_process_pid = run_background_command(["/usr/bin/runsvdir", "-P", ENTRYPOINT_PROCESS_DIR])

        if not restart_processes:
            info("Waiting services to start ...")
            done = False
            while not done:
                done = subprocess.run("/usr/bin/sv status %s/* | grep -q -v '^run:'" %
                                    ENTRYPOINT_PROCESS_DIR, shell=True).returncode != 0

            info("Modifying settings to not restart terminated services ...")
            subprocess.run("/usr/bin/sv once %s/*" %
                              ENTRYPOINT_PROCESS_DIR, shell=True, check=True)

        runit_process_exited, exit_status = run_main_command_or_wait_background_process(main_command, runit_process_name, runit_process_pid)

    finally:
        shutdown_runit_services()

        if not runit_process_exited:
            stop_child_process(runit_process_name, runit_process_pid)

        wait_runit_services_shutdown()

    sys.exit(exit_status)


def run_single_process_container(main_command, service = ""):
    container_process_exited = False
    container_process_name = None
    container_process_pid = None
    exit_status = None

    try:
        if not service:
            # If we are here ENTRYPOINT_PROCESS_DIR should have only one subdirectory.
            for s in listdir(ENTRYPOINT_PROCESS_DIR):
                service = s

        container_process = os.path.join(ENTRYPOINT_PROCESS_DIR, service, "run")
        container_process_name, container_process_pid = run_background_command([container_process])

        container_process_exited, exit_status = run_main_command_or_wait_background_process(main_command, container_process_name, container_process_pid)

    finally:
        if not container_process_exited:
            stop_child_process(container_process_name, container_process_pid)

    sys.exit(exit_status)


def run_no_process_container(main_command):
    if len(main_command) == 0:
        main_command = ["bash"]  # Run bash by default.

    exit_status = run_command(main_command)
    sys.exit(exit_status)


def run_lifecycle_commands(commands, lifecycle):
    if not commands:
        return

    for command in commands:
        info("Running pre-%s command %s ... " % (lifecycle, command))
        run_command(shlex.split(command))


def main(args):
    info("Container image: %s" % get_container_image())

    set_log_env()

    if args.unsecure_fast_write:
        info("Unsecure fast write is enabled: setting LD_PRELOAD=libeatmydata.so")
        os.environ["LD_PRELOAD"] = "libeatmydata.so"

    if args.debug is not None:
        subprocess.run("/container/tools/install-debug-tools %s" %
                       " ".join(args.debug), shell=True, check=True)

    try:
        debug(subprocess.run("/container/tools/install-services",
              shell=True, capture_output=True, text=True, check=True).stdout)
    except subprocess.CalledProcessError as e:
        warning(e.stdout)

    if not args.skip_env_files:
        import_env_files()

    debug(dump_env())

    if args.run_only_service:
        info("Going to run only %s service" % args.run_only_service)

        if not process_exists(args.run_only_service):
            error("Service %s not found.\nAvailable service(s): %s" % (args.run_only_service, ", ".join(process_list())))
            sys.exit(1)

    if not args.skip_startup:
        run_lifecycle_commands(args.pre_startup_cmds, "startup")
        run_scripts(ENTRYPOINT_STARTUP_DIR, args.run_only_service)

    if not args.skip_process:
        run_lifecycle_commands(args.pre_process_cmds, "process")

        if is_single_process_container() or args.run_only_service:
            run_single_process_container(args.main_command, args.run_only_service)
        elif is_multiprocess_container():
            run_multiprocess_container(args.main_command, args.restart_processes)
        else:
            run_no_process_container(args.main_command)


# Command line options.
parser = argparse.ArgumentParser(prog="", description="Container image: %s" % get_container_image(
), epilog="Built with osixia/baseimage (https://github.com/osixia/container-baseimage) 🐳✨🌴")

parser.add_argument(metavar="MAIN_COMMAND", dest="main_command", nargs="*",
                    help="the main command to run in addition of container processes, default: /bin/bash if the container have no process, none otherwise")

parser.add_argument("-v", "--version", action='version',
                    version=get_container_image(), help="print container image version")

generator_group = parser.add_argument_group("generator")
if not is_single_process_container() and not is_multiprocess_container():
    generate_help = "generate base templates for single process image, default: dockerfile"
    generate_multiprocess_help = "generate base templates for multiprocess image, default: dockerfile"
    generate_child_help = help=argparse.SUPPRESS
else:
    generate_help = help=argparse.SUPPRESS
    generate_multiprocess_help = help=argparse.SUPPRESS
    generate_child_help = "generate child image templates, default: dockerfile"

generator_group.add_argument("-gen", "--generate", choices=["dockerfile", "dagger.io"], nargs='?', const="dockerfile", dest="generate",
                            help=generate_help)
generator_group.add_argument("-gmu", "--generate-multiprocess", choices=["dockerfile", "dagger.io"], nargs='?', const="dockerfile", dest="generate_multiprocess",
                            help=generate_multiprocess_help)
generator_group.add_argument("-gch", "--generate-child", choices=["dockerfile", "dagger.io"], nargs='?', const="dockerfile", dest="generate_child",
                        help=generate_child_help)

generator_group.add_argument("-gse", "--generate-service", metavar="SERVICE", nargs='?', const="service-1", dest="generate_service", action="append",
                             help="generate service templates with name passed as argument, default: service-1")
generator_group.add_argument("-gsa", "--generate-service-available", metavar="SERVICE", nargs='?', const="service-1", dest="generate_service_available", action="append",
                             help="generate service available templates with name passed as argument, default: service-1")

environment_group = parser.add_argument_group("environment variables")
environment_group.add_argument("-e", "--skip-env-files", dest="skip_env_files",
                               action="store_true",
                               help="skip getting environment variables values from .env file(s)")

lifecycle_group = parser.add_argument_group("container lifecycle")
lifecycle_group.add_argument("-s", "--skip-startup", dest="skip_startup",
                             action="store_true",
                             help="skip running pre-startup-cmd and service(s) startup.sh script(s)")
lifecycle_group.add_argument("-p", "--skip-process", dest="skip_process",
                             action="store_true",
                             help="skip running pre-process-cmd and service(s) process.sh script(s)")
lifecycle_group.add_argument("-f", "--skip-finish", dest="skip_finish",
                             action="store_true",
                             help="skip running pre-finish-cmd and service(s) finish.sh script(s)")
lifecycle_group.add_argument("-c", "--run-only-lifecycle", choices=["startup", "process", "finish"], dest="run_only_lifecycle",
                             help="run only one lifecycle type of pre-command and script(s) file(s) and ignore others")

commands_group = parser.add_argument_group("commands hooks")
commands_group.add_argument("-xps", "--pre-startup-cmd", metavar="COMMAND", dest="pre_startup_cmds", action="append",
                            help="run command passed as argument before startup.sh script(s)")
commands_group.add_argument("-xpp", "--pre-process-cmd", metavar="COMMAND", dest="pre_process_cmds", action="append",
                            help="run command passed as argument before process.sh script(s)")
commands_group.add_argument("-xpf", "--pre-finish-cmd", metavar="COMMAND", dest="pre_finish_cmds", action="append",
                            help="run command passed as argument before finish.sh script(s)")
commands_group.add_argument("-xpe", "--pre-exit-cmd", metavar="COMMAND", dest="pre_exit_cmds", action="append",
                            help="run command passed as argument before container exits")

process_group = parser.add_argument_group("process execution")
process_group.add_argument("-a", "--keep-alive", dest="keep_alive",
                         action="store_true",
                         help="keep alive container after all processes have exited")
process_group.add_argument("-k", "--no-kill-all-on-exit", dest="kill_all_on_exit",
                         action="store_false",
                         help="don't kill all processes on the system upon exiting")
process_group.add_argument("-r", "--no-restart-processes", dest="restart_processes",
                         action="store_false",
                         help="don't automatically restart failed services process.sh scripts (multiprocess images only)")
process_group.add_argument("-x", "--run-only-service", metavar="SERVICE", dest="run_only_service",
                             help="run only service passed as argument and ignore others (multiprocess images only)")

ci_cd_group = parser.add_argument_group("ci/cd")
ci_cd_group.add_argument("-w", "--unsecure-fast-write", dest="unsecure_fast_write",
                         action="store_true",
                         help="disable fsync and friends with eatmydata LD_PRELOAD library")

debug_group = parser.add_argument_group("debugging")
debug_group.add_argument("-d", "--debug",  metavar="EXTRA PACKAGE", dest="debug", nargs="*",
                         help="set log level to debug and install debug tools (curl less procps psmisc strace vim) with optional extra packages passed as argument")

logs_group = parser.add_argument_group("logging")
logs_group.add_argument("-j", "--logjson", dest="log_json",
                        action="store_true",
                        help="set log format to json")
logs_group.add_argument("-l", "--loglevel", choices=log_level_switcher.keys(), dest="log_level", default=log_level_switcher_inv.get(log_level),
                        help="set log level, default: %s" % log_level_switcher_inv.get(log_level))

args = parser.parse_args()

# Set logs level and output type.
if args.debug is not None and log_level_switcher.get(args.log_level) < LOG_LEVEL_DEBUG:
    args.log_level = log_level_switcher_inv.get(LOG_LEVEL_DEBUG)

log_level = log_level_switcher.get(args.log_level)
log_json = args.log_json

# Generator options.
# Must be called before set_log_env,
# so container environment variables are not replaced by envsubst-templates
generator(args)

# run only service is only available for single process images
if args.run_only_service and is_single_process_container():
    args.run_only_service = ""

# Validate and set run-only-lifecycle options.
if args.run_only_lifecycle is not None:
    if args.run_only_lifecycle == "startup" and args.skip_startup:
        error("When '--run-only-lifecycle startup' is set --skip-startup can't be set.")
        sys.exit(1)

    elif args.run_only_lifecycle == "process" and args.skip_startup:
        error("When '--run-only-lifecycle process' is set --skip-process can't be set.")
        sys.exit(1)

    elif args.run_only_lifecycle == "finish" and args.skip_startup:
        error("When '--run-only-lifecycle finish' is set --skip-finish can't be set.")
        sys.exit(1)

    if args.run_only_lifecycle == "startup":
        args.skip_process = True
        args.skip_finish = True
    elif args.run_only_lifecycle == "process":
        args.skip_startup = True
        args.skip_finish = True
    elif args.run_only_lifecycle == "finish":
        args.skip_startup = True
        args.skip_process = True

# Run main function.
signal.signal(signal.SIGTERM, lambda signum,
              frame: ignore_signals_and_raise_keyboard_interrupt("SIGTERM"))
signal.signal(signal.SIGINT, lambda signum,
              frame: ignore_signals_and_raise_keyboard_interrupt("SIGINT"))
signal.signal(signal.SIGALRM, lambda signum, frame: raise_alarm_exception())

exit_code = 0

try:
    main(args)

except SystemExit as e:
    exit_code = e.code

except KeyboardInterrupt:
    warning("Container entrypoint init system aborted.")
    exit(2)

finally:
    if not args.skip_finish:
        run_lifecycle_commands(args.pre_finish_cmds, "finish")
        run_scripts(ENTRYPOINT_FINISH_DIR, args.run_only_service)

    if args.kill_all_on_exit:
        kill_all_processes(KILL_ALL_PROCESSES_TIMEOUT)

    run_lifecycle_commands(args.pre_exit_cmds, "exit")

    if args.keep_alive:
        try:
            info("All processes have exited, keep container alive ...")
            while True:
                time.sleep(60)
                pass
        except:
            warning("Keep alive process ended ☠")

    exit(exit_code)
